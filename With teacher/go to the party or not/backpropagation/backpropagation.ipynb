{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adding libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creation class PartyNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartyNN(object):\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        \n",
    "        self.weights_0_1 = np.random.normal(0.0, 2 ** -0.5, (2, 3))\n",
    "        self.weights_1_2 = np.random.normal(0.0, 1, (1, 2))\n",
    "        self.sigmoid_mapper = np.vectorize(self.sigmoid)\n",
    "        self.learning_rate = np.array([learning_rate])\n",
    "    \n",
    "    \n",
    "    ###Activation function\n",
    "    def sigmoid(self, x):\n",
    "        \n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    ###Prediction (at least try)\n",
    "    def predict(self, inputs):\n",
    "        \n",
    "        inputs_1 = np.dot(self.weights_0_1, inputs)\n",
    "        outputs_1 = self.sigmoid_mapper(inputs_1)\n",
    "        \n",
    "        inputs_2 = np.dot(self.weights_1_2, outputs_1)\n",
    "        outputs_2 = self.sigmoid_mapper(inputs_2)\n",
    "        return outputs_2\n",
    "    \n",
    "    ###Backpropagation \n",
    "    def train(self, inputs, expected_predict): \n",
    "       \n",
    "        inputs_1 = np.dot(self.weights_0_1, inputs)\n",
    "        outputs_1 = self.sigmoid_mapper(inputs_1)\n",
    "        \n",
    "        inputs_2 = np.dot(self.weights_1_2, outputs_1)\n",
    "        outputs_2 = self.sigmoid_mapper(inputs_2)\n",
    "        actual_predict = outputs_2[0]\n",
    "        error_layer_2 = np.array([actual_predict - expected_predict])\n",
    "        gradient_layer_2 = actual_predict * (1 - actual_predict)\n",
    "        weights_delta_layer_2 = error_layer_2 * gradient_layer_2  \n",
    "        self.weights_1_2 -= (np.dot(weights_delta_layer_2, outputs_1.reshape(1, len(outputs_1)))) * self.learning_rate\n",
    "       \n",
    "        error_layer_1 = weights_delta_layer_2 * self.weights_1_2\n",
    "        gradient_layer_1 = outputs_1 * (1 - outputs_1)\n",
    "        weights_delta_layer_1 = error_layer_1 * gradient_layer_1\n",
    "        self.weights_0_1 -= np.dot(inputs.reshape(len(inputs), 1), weights_delta_layer_1).T  * self.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    \n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    ([0, 0, 0], 0),\n",
    "    ([0, 0, 1], 1),\n",
    "    ([0, 1, 0], 0),\n",
    "    ([0, 1, 1], 0),\n",
    "    ([1, 0, 0], 1),\n",
    "    ([1, 0, 1], 1),\n",
    "    ([1, 1, 0], 0),\n",
    "    ([1, 1, 1], 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.9, Training loss: 0.001"
     ]
    }
   ],
   "source": [
    "epochs = 6000\n",
    "learning_rate = 0.08\n",
    "\n",
    "network = PartyNN(learning_rate=learning_rate)\n",
    "for e in range(epochs):\n",
    "    inputs_ = []\n",
    "    correct_predictions = []\n",
    "    for input_stat, correct_predict in train:\n",
    "        network.train(np.array(input_stat), correct_predict)\n",
    "        inputs_.append(np.array(input_stat))\n",
    "        correct_predictions.append(np.array(correct_predict))\n",
    "    train_loss = MSE(network.predict(np.array(inputs_).T), np.array(correct_predictions))\n",
    "    sys.stdout.write(\"\\rProgress: {}, Training loss: {}\".format(str(100 * e/float(epochs))[:4], str(train_loss)[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input: [0, 0, 0] the prediction is: [False], expected: False\n",
      "For input: [0, 0, 1] the prediction is: [ True], expected: True\n",
      "For input: [0, 1, 0] the prediction is: [False], expected: False\n",
      "For input: [0, 1, 1] the prediction is: [False], expected: False\n",
      "For input: [1, 0, 0] the prediction is: [ True], expected: True\n",
      "For input: [1, 0, 1] the prediction is: [ True], expected: True\n",
      "For input: [1, 1, 0] the prediction is: [False], expected: False\n",
      "For input: [1, 1, 1] the prediction is: [ True], expected: True\n"
     ]
    }
   ],
   "source": [
    "for input_stat, correct_predict in train:\n",
    "    print(\"For input: {} the prediction is: {}, expected: {}\".format(\n",
    "          str(input_stat), \n",
    "          str(network.predict(np.array(input_stat)) > .5),\n",
    "          str(correct_predict == 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
