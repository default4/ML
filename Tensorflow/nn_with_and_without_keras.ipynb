{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12318e9b0c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('', one_hot=True)\n",
    "\n",
    "image = mnist.train.images[7].reshape([28, 28]);\n",
    "plt.gray()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.37254903 0.8862746  0.9921569  0.9921569\n",
      " 0.8862746  0.         0.         0.36078432 0.0509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01960784 0.29803923\n",
      " 0.97647065 0.9921569  0.9921569  0.9921569  0.8862746  0.\n",
      " 0.41176474 0.9843138  0.854902   0.34117648 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[7][150:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Neural network configuration\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "batch_size = 128 ###Number of objects in one epoch\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "num_input = 784 \n",
    "num_classes = 10\n",
    "\n",
    "X = tf.compat.v1.placeholder('float', [None, num_input])\n",
    "Y = tf.compat.v1.placeholder('float', [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random.normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2])),\n",
    "    'output': tf.Variable(tf.random.normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
    "    'output': tf.Variable(tf.random.normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Neural network\n",
    "def network(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    output_layer = tf.matmul(layer_2, weights['output']) + biases['output']\n",
    "\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = network(X)\n",
    "\n",
    "###Loss function (minimizing of cross entropy)\n",
    "loss = tf.reduce_mean(\n",
    "    input_tensor=tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y\n",
    "    )\n",
    ")\n",
    "\n",
    "###Optimization algorithm\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss) ###Minimization of entropy with optimizer\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(input=logits, axis=1), tf.argmax(input=Y, axis=1))\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: train accuracy = 0.3113272786140442\n",
      "Epoch #50: train accuracy = 0.8371454477310181\n",
      "Epoch #100: train accuracy = 0.8498363494873047\n",
      "Epoch #150: train accuracy = 0.8556181788444519\n",
      "Epoch #200: train accuracy = 0.8472909331321716\n",
      "Epoch #250: train accuracy = 0.8718545436859131\n",
      "Epoch #300: train accuracy = 0.8643090724945068\n",
      "Epoch #350: train accuracy = 0.8461272716522217\n",
      "Epoch #400: train accuracy = 0.8583090901374817\n",
      "Epoch #450: train accuracy = 0.8434545397758484\n",
      "Epoch #500: train accuracy = 0.8489454388618469\n",
      "Epoch #550: train accuracy = 0.8454181551933289\n",
      "Epoch #600: train accuracy = 0.8521999716758728\n",
      "Epoch #650: train accuracy = 0.8426727056503296\n",
      "Epoch #700: train accuracy = 0.8380727171897888\n",
      "Epoch #750: train accuracy = 0.8507999777793884\n",
      "Epoch #800: train accuracy = 0.8303636312484741\n",
      "Epoch #850: train accuracy = 0.8304363489151001\n",
      "Epoch #900: train accuracy = 0.833690881729126\n",
      "Epoch #950: train accuracy = 0.862709105014801\n",
      "Test accuracy = 0.8535000085830688\n"
     ]
    }
   ],
   "source": [
    "###Learning\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train, feed_dict={X: batch_x, Y: batch_y})\n",
    "        \n",
    "        ###Every 50 epochs print debugging information\n",
    "        if epoch % 50 == 0:\n",
    "            train_accuracy = sess.run(\n",
    "                accuracy, \n",
    "                feed_dict={\n",
    "                    X: mnist.train.images,\n",
    "                    Y: mnist.train.labels\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print('Epoch #{}: train accuracy = {}'.format(epoch, train_accuracy))\n",
    "\n",
    "    print('Test accuracy = {}'.format(\n",
    "        sess.run(\n",
    "            accuracy,\n",
    "            feed_dict={\n",
    "                X: mnist.test.images,\n",
    "                Y: mnist.test.labels\n",
    "            }\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "###Neural network configuretion with Keras\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model creation\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(784,))) ###1 layer with 512 neurons\n",
    "model.add(tf.keras.layers.Dropout(0.2)) ###Throw random neurons so that they are less correlated with each other\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2498 - acc: 0.9258 - val_loss: 0.1034 - val_acc: 0.9674\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1017 - acc: 0.9682 - val_loss: 0.0793 - val_acc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "###Model compilation\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "_ = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07930966514158062\n",
      "Test accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
